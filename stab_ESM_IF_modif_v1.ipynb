{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StevenVGan/bioai-sandbox/blob/main/stab_ESM_IF_modif_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b><font color='#009e74'>Absolute folding stabiity prediction via generative models</font></b>\n",
        "Colaboratory implementation of : **Cagiada M., Ovchinnikov S. & Lindorff-Larsen K.** - [Predicting absolute protein folding stability using generative models\n",
        "](https://doi.org/10.1002/pro.5233), Protein Science 34.1 (2025): e5233.. Source code is available on the [Github](https://github.com/KULL-Centre/_2024_cagiada_stability) page of the project.\n",
        "\n",
        "Prediction of the absolute stability for a target folding given a protein sequence.\n",
        "\n",
        "The Colab uses ESM-IF and the following measure:\n",
        "\n",
        "$\\Delta G_{f-u} = \\sum_{i}^{N} \\mathscr{L}_i^{WT}$\n",
        "\n",
        "where $\\mathscr{L}_i^{WT}$ is the amino acid likelihood extracted from ESM-IF for the wild-type amino acid at position i, to evaluate the absolute stability ($\\Delta G_{f-u}$) for a specific protein folding.\n",
        "\n"
      ],
      "metadata": {
        "id": "AcjxZ9mXikrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional notes:\n",
        "\n",
        "- Run this notebook  <b><font color='#d55c00'>preferabilly</font></b> in a Colab GPU session (go to page menu: `Runtime`->  `Change runtime type` -> select `GPU` and confirm.\n",
        "\n",
        "- Cells labelled <b><font color='#f0e422'>PRELIMINARY OPERATIONS </font></b>  have to be run <b><font color='#d55c00'>ONCE</font></b>  at the start and skipped for new predictions.\n",
        "\n",
        "- A <b><font color='#d55c00'>kernel restart is expected</font></b> after the cell: \"<b><font color='#f0e422'>PRELIMINARY OPERATIONS:</font> Install Condalab\" </b> to complete the installation of the package. Please run this cell once by its own and then continue with the rest of the cells.\n",
        "\n",
        "- Multiple predictions can be run in a single session, but only <b><font color='#d55c00'>ONE</font></b> pdb at a time will be processed by the notebook.\n",
        "\n",
        "- A <b><font color='#d55c00'>new run</font></b> can be perform input direcly the new structure in the pdb upload cell and run the prediction cell again (you don't need to run the <b><font color='#f0e422'>PRELIMINARY OPERATIONS </font></b> again.\n",
        "\n",
        "- If you wish to download the predictions run the <b><font color='#56b4e9'>DOWNLOAD RESULTS </font></b> and <b>ALL</b>\n",
        " the predictions made in the session will be dowloaded.\n",
        "\n",
        "- To evaluate absolute stability the model uses an input structure in PDB format, usually in the form of an [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) predicted structure, if you have an experimentally resolved structure please consider generating an AF2 prediction using your structure as a template.\n",
        "\n",
        "- The absolute stability can only be predicted for <b><font color='#d55c00'>one</font></b> chain at a time, but the input structure protein can be either a single chain or a multi-chain complex (the remaining chains would not be taken into account during the prediction).\n",
        "\n",
        "- The output of a prediction is displayed below the prediction cell and saved in an output file which includes the absolute stability (as a sum of likelihoods and in kcal/mol) and the contribution to the total stability for each residue (as a likelihood).\n",
        "\n",
        "- An **alternative sequence** can be used in the input instead of the sequence extracted from the PDB file, **HOWEVER** it must be the same length as the original sequence.\n",
        "****"
      ],
      "metadata": {
        "id": "a4dANSUAinaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#f0e422'>PRELIMINARY OPERATIONS:</font> Install condalab\n",
        "#@markdown Run the cell to install conda-colab, now (from Oct 2024) required for torch dependencies <b>(walltime ~1 min)</b>\n",
        "\n",
        "#@markdown <font color='#d55c00'>N.B.:</font> <b>the kernel WILL RESTART</b> at the end of the installation of CondaLab, <b>undoing</b> any other cell process in the queue. When this is complete, continue with executing the remaining <b><font color='#f0e422'>PRELIMINARY OPERATIONS</font></b> cells\n",
        "\n",
        "!pip install -q condacolab\n",
        "\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "G35b4siEczk2",
        "cellView": "form",
        "outputId": "0e991539-fe95-4d52-a22b-71be5370e770",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:09\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "40_BsFRU0VEO",
        "outputId": "044a868d-93c5-4d1b-da1b-968d8cf3c09b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch 2.9.0, CUDA 12.8\n",
            "Downloading model params (background)...\n",
            "installing libs...\n",
            "Installing torch_geometric (may take 1-2 min)...\n",
            "...torch_geometric done\n",
            "Ensuring dependencies (torch_geometric, biopython, biotite, esm)...\n",
            "importing the model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/esm/pretrained.py:216: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installations succeeded\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title <b><font color='#f0e422'>PRELIMINARY OPERATIONS:</font> Install dependencies\n",
        "\n",
        "#@markdown Run the cell to install all the extra necessaries packages <b>(~15 mins)</b>, including:\n",
        "#@markdown - ESM-IF (library and parameters)\n",
        "#@markdown - Torch libraries: torch-scatter,-sparse,-cluster,spline-conv,-geometric\n",
        "#@markdown - Python libraries: biopython, biotite\n",
        "\n",
        "import os,time,subprocess,re,sys,shutil\n",
        "from google.colab import files\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version) if CUDA_version else \"cpu\"\n",
        "\n",
        "print(f\"PyTorch {TORCH}, CUDA {CUDA_version or 'cpu'}\")\n",
        "\n",
        "IF_model_name = \"esm_if1_gvp4_t16_142M_UR50.pt\"\n",
        "\n",
        "if not os.path.isfile(IF_model_name):\n",
        "  # download esmfold params\n",
        "  print(\"Downloading model params (background)...\")\n",
        "  os.system(\"apt-get install -y -qq aria2 2>/dev/null\")\n",
        "  os.system(f\"aria2c -x 16 https://sid.erda.dk/share_redirect/eIZVVNEd8B --out={IF_model_name} &\")\n",
        "\n",
        "  if not os.path.isfile(\"finished_install\"):\n",
        "    # install libs (use kernel's Python - os.system installs to wrong env with condacolab)\n",
        "    print(\"installing libs...\")\n",
        "    pip_install = [sys.executable, \"-m\", \"pip\", \"install\"]  # no -q: show progress\n",
        "\n",
        "    # PyG: minimal install first (fast). PyG 2.3+ has MessagePassing without torch-scatter.\n",
        "    print(\"Installing torch_geometric (may take 1-2 min)...\")\n",
        "    subprocess.run(pip_install + [\"torch_geometric\"], check=True)\n",
        "    print('...torch_geometric done')\n",
        "    subprocess.run(pip_install + [\"biopython\", \"biotite\"], check=True)\n",
        "    subprocess.run(pip_install + [\"git+https://github.com/matteo-cagiada/esm.git\"], check=True)\n",
        "    os.system(\"touch finished_install\")\n",
        "\n",
        "    #wait for Params to finish downloading...\n",
        "    wait_count = 0\n",
        "    while not os.path.isfile(IF_model_name):\n",
        "      time.sleep(5)\n",
        "      wait_count += 1\n",
        "      if wait_count % 6 == 0:\n",
        "        print(f\"  ...waiting for model download ({wait_count*5}s)\")\n",
        "    if os.path.isfile(f\"{IF_model_name}.aria2\"):\n",
        "      print(\"Downloading params...\")\n",
        "    while os.path.isfile(f\"{IF_model_name}.aria2\"):\n",
        "      time.sleep(5)\n",
        "\n",
        "## Ensure all deps are in kernel's Python (runs every time - idempotent, shows progress)\n",
        "pip_install = [sys.executable, \"-m\", \"pip\", \"install\"]  # no -q: show progress\n",
        "print(\"Ensuring dependencies (torch_geometric, biopython, biotite, esm)...\")\n",
        "subprocess.run(pip_install + [\"torch_geometric\", \"biopython\", \"biotite\", \"git+https://github.com/matteo-cagiada/esm.git\"], check=True)\n",
        "\n",
        "import esm\n",
        "\n",
        "from esm.inverse_folding.util import load_structure, extract_coords_from_structure,CoordBatchConverter\n",
        "from esm.inverse_folding.multichain_util import extract_coords_from_complex,_concatenate_coords,load_complex_coords\n",
        "\n",
        "\n",
        "print(\"importing the model\")\n",
        "\n",
        "model, alphabet = esm.pretrained.load_model_and_alphabet(IF_model_name)\n",
        "model.eval().cuda().requires_grad_(False)\n",
        "\n",
        "print(\"--> Installations succeeded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#f0e422'>PRELIMINARY OPERATIONS:</font> Load EXTRA functions\n",
        "#@markdown Run the cell to load the required functions\n",
        "\n",
        "def run_model(coords,sequence,model,cmplx=False,chain_target='A'):\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    batch_converter = CoordBatchConverter(alphabet)\n",
        "    batch = [(coords, None, sequence)]\n",
        "    coords, confidence, strs, tokens, padding_mask = batch_converter(\n",
        "        batch, device=device)\n",
        "\n",
        "    prev_output_tokens = tokens[:, :-1].to(device)\n",
        "    target = tokens[:, 1:]\n",
        "    target_padding_mask = (target == alphabet.padding_idx)\n",
        "\n",
        "    logits, _ = model.forward(coords, padding_mask, confidence, prev_output_tokens)\n",
        "\n",
        "    logits_swapped=torch.swapaxes(logits,1,2)\n",
        "    token_probs = torch.softmax(logits_swapped, dim=-1)\n",
        "\n",
        "    return token_probs\n",
        "\n",
        "def score_variants(sequence,token_probs,alphabet):\n",
        "\n",
        "    aa_list=[]\n",
        "    wt_scores=[]\n",
        "    skip_pos=0\n",
        "\n",
        "    alphabetAA_L_D={'-':0,'_' :0,'A':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'K':9,'L':10,'M':11,'N':12,'P':13,'Q':14,'R':15,'S':16,'T':17,'V':18,'W':19,'Y':20}\n",
        "    alphabetAA_D_L={v: k for k, v in alphabetAA_L_D.items()}\n",
        "\n",
        "    for i,n in enumerate(sequence):\n",
        "      aa_list.append(n+str(i+1))\n",
        "      score_pos=[]\n",
        "      for j in range(1,21):\n",
        "          score_pos.append(masked_absolute(alphabetAA_D_L[j],i, token_probs, alphabet))\n",
        "          if n == alphabetAA_D_L[j]:\n",
        "            WT_score_pos=score_pos[-1]\n",
        "\n",
        "      wt_scores.append(WT_score_pos)\n",
        "\n",
        "    return aa_list, wt_scores\n",
        "\n",
        "def masked_absolute(mut, idx, token_probs, alphabet):\n",
        "\n",
        "    mt_encoded = alphabet.get_idx(mut)\n",
        "\n",
        "    score = token_probs[0,idx, mt_encoded]\n",
        "    return score.item()"
      ],
      "metadata": {
        "id": "lWXN38psLY3u",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'> DATA UPLOADING</font>\n",
        "#@markdown Fill in the fields and run the cell to set up the job name, import the structure, select the chain and upload an alternative sequence (not mandatory).\n",
        "jobname='YP_0097243901_ref_RBD_SWISS'#@param {type:\"string\"}\n",
        "\n",
        "#@markdown Choose between <b><font color='#d55c00'> ONE</font></b> of the possible input sources for the target pdb and <b><font color='#d55c00'>leave the other cells empty or unmarked</font></b>\n",
        "#@markdown - AlphaFold2 PDB (v4) via Uniprot ID:\n",
        "AF_ID =''#@param {type:\"string\"}\n",
        "#@markdown - Upload custom PDB\n",
        "AF_custom =True#@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown Select target chain (default A)\n",
        "chain_id='A' #@param {type:'string'}\n",
        "\n",
        "#@markdown Upload an alternative sequence for the structure (leave empty if not used)\n",
        "alternative_sequence='' #@param {type:'string'}\n",
        "\n",
        "input_path = f\"/content/inputs\"\n",
        "if not os.path.exists(input_path):\n",
        "  os.mkdir(input_path)\n",
        "\n",
        "output_path = f\"/content/outputs\"\n",
        "if not os.path.exists(output_path):\n",
        "  os.mkdir(output_path)\n",
        "\n",
        "if AF_custom:\n",
        "  print('Upload PDB file:')\n",
        "  uploaded_AF = files.upload()\n",
        "  for fn in uploaded_AF.keys():\n",
        "    os.rename(fn, f\"/content/inputs/query_protein.pdb\")\n",
        "    output_name_pdb=fn\n",
        "    print('... PDB file correctly loaded')\n",
        "elif (AF_ID !='') and (len(AF_ID)>=6) :\n",
        "    subprocess.call(['curl','-s','-f',f'https://alphafold.ebi.ac.uk/files/AF-{AF_ID}-F1-model_v4.pdb','-o','/content/inputs/query_protein.pdb'])\n",
        "    output_name_pdb=f'AF-{AF_ID}-F1-model_v4.pdb'\n",
        "else:\n",
        "  sys.exit(f'ERROR: any PDB uploaded, please select one of the above inputs')\n",
        "\n",
        "structure = load_structure(f\"/content/inputs/query_protein.pdb\", chain_id)\n",
        "coords_structure, sequence_structure = extract_coords_from_structure(structure)\n",
        "\n",
        "if alternative_sequence != '':\n",
        "  if ' ' in alternative_sequence:\n",
        "    sys.exit ('!!!! Run interrupted: please check input sequence before proceeding space characters detected!!!!')\n",
        "\n",
        "  assert len(alternative_sequence) == len(sequence_structure), \"Alternative sequence length doesn't match pdb sequence length, run interrupted!\"\n",
        "\n",
        "  sequence_structure = alternative_sequence\n",
        "  print('... Alternative sequence loaded correctly')\n",
        "\n",
        "print('... Target sequence:', sequence_structure)\n",
        "#@markdown ****"
      ],
      "metadata": {
        "id": "fbmpNhrvbKil",
        "cellView": "form",
        "outputId": "aeb41840-775d-4bda-bc77-2315e4148c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload PDB file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-71cf110d-f995-47f8-901b-07ebb34469ed\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-71cf110d-f995-47f8-901b-07ebb34469ed\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model.pdb to model.pdb\n",
            "... PDB file correctly loaded\n",
            "... Target sequence: RVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'> MODEL RUN</font>\n",
        "#@markdown Run this cell to evaluate the ŒîG for the selected structure and sequence\n",
        "\n",
        "#@markdown **N.B:** the ŒîG value will be output in the scale of the chosen metric and also in kcal/mol (see the manuscript for how we converted the scale)\n",
        "a=0.10413378327743603 ## fitting param from the manuscript to convert IF score scale to kcal/mol\n",
        "b=0.6162549378400894 ## fitting param from the manuscript to convert IF score scale to kcal/mol\n",
        "\n",
        "prob_tokens = run_model(coords_structure,sequence_structure,model,chain_target=chain_id)\n",
        "aa_list, wt_scores = score_variants(sequence_structure,prob_tokens,alphabet)\n",
        "\n",
        "dg_IF= np.nansum(wt_scores)\n",
        "print('ŒîG predicted (likelihoods sum): ',dg_IF)\n",
        "\n",
        "dg_kcalmol= a * dg_IF + b\n",
        "\n",
        "print('ŒîG predicted (kcal/mol): ', dg_kcalmol)\n",
        "\n",
        "aa_list_export=aa_list+['dG_IF','dG_kcalmol']\n",
        "wt_scores_export=wt_scores+[dg_IF,dg_kcalmol]\n",
        "\n",
        "df_export=pd.DataFrame({'Residue':aa_list_export,'score':wt_scores_export})\n",
        "\n",
        "df_export.to_csv(f\"outputs/\"+f\"{jobname}_dG_pos_scores_and_total.csv\",sep=',')\n",
        "## move pdb to output folder\n",
        "try:\n",
        "  os.rename(f\"inputs/query_protein.pdb\",f\"outputs/{output_name_pdb}\")\n",
        "except:\n",
        "  print('!!!! Data not saved, please re-upload the structure by running the uploading cell')\n"
      ],
      "metadata": {
        "id": "ocOnty1TP9Ec",
        "cellView": "form",
        "outputId": "8061f936-a57b-4643-d2cb-738a1137de68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ŒîG predicted (likelihoods sum):  87.47504857147578\n",
            "ŒîG predicted (kcal/mol):  9.725362687965339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#56b4e9'>DOWNLOAD RESULTS </font></b>\n",
        "#@markdown **N.B:** This will download **ALL** the predictions produced during the current session as zip file\n",
        "os.system( \"zip -r {} {}\".format( f\"dG_runs.zip\" , f\"outputs\" ) )\n",
        "files.download(f\"dG_runs.zip\")\n"
      ],
      "metadata": {
        "id": "HdIPxqSE6zWi",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "25268cdb-523d-4e51-d528-c36e0b90482d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f460eca-c087-4921-b60e-1aaa912c2a2d\", \"dG_runs.zip\", 34685)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><font color='#56b4e9'>EXTRA </font></b>\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Output of the colab**\n",
        "\n",
        "When a prediction is complete, the output files generated with the run are stored in the `/content/outputs` folder. When the <b><font color='#56b4e9'>DOWNLOAD RESULTS </font></b> cell is executed, all files are downloaded at once.\n",
        "\n",
        "The output files stored for each run are\n",
        "- the pdb used as input\n",
        "- the fasta file of the query sequence\n",
        "- the prediction output file\n",
        "\n",
        "**Prediction file Format**\n",
        "\n",
        "The output csv file consists of two columns, where the wild-type amino acid probability for each position is reported, and then at the bottom both the $\\Delta G$ as the sum of the wild-type probabilities and in kcal/mol are reported.\n",
        "\\\\\n",
        "\n",
        ">OUTPUT FILE EXAMPLE:\n",
        "\n",
        ">For a target protein with 45 residues, the scores file should be formatted like this:\n",
        "\n",
        ">Residue  Likelihood\n",
        "\n",
        ">M1               0.4  \n",
        "A2                0.2\n",
        "D3                0.3  \n",
        "C5                0.9   \n",
        "..  \n",
        "..  \n",
        "Y45               0.3\n",
        "dG_IF       201\n",
        "dG_kcalmol  13\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Updates:**\n",
        "\n",
        "- March 2025: Code updated to fit new pytorch + cuda enviroment on Colab\n",
        "\n",
        "\n",
        "- Oct 2024: Changed installation from pip to colab-conda for pytorch dependencies (an update to Colab made the walltime too high with pip)\n",
        "\n",
        "\\\\\n",
        "**Known problems:**\n",
        "\n",
        "- Predictions on multi-domain proteins or proteins with complex folding kinetics show an absolute stability overestimated compared to the real one.\n",
        "\n",
        "- Predictions are limited to proteins with 1023 residues (Max protein size for the ESM-IF language model)\n",
        "\n",
        "\\\\\n",
        "\n",
        "**License:**\n",
        "\n",
        "The $ŒîG$ predictor, and ESM-IF source code and parameters are licensed under the permissive Apache Licence, Version 2.0.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Bugs:**\n",
        "\n",
        "For any bugs please report the issue on the project [Github](https://github.com/KULL-Centre/_2024_cagiada_stability) or contact one of the listed authors in the connected [manuscript](https://doi.org/).\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Citing this work:**\n",
        "\n",
        "If you use our model please cite:\n",
        "\n",
        "Cagiada, Matteo, Sergey Ovchinnikov, and Kresten Lindorff‚ÄêLarsen. \"Predicting absolute protein folding stability using generative models.\" Protein Science 34.1 (2025): e5233.\n",
        "\n",
        "```\n",
        "@article{cagiada2025predicting,\n",
        "  title={Predicting absolute protein folding stability using generative models},\n",
        "  author={Cagiada, Matteo and Ovchinnikov, Sergey and Lindorff-Larsen, Kresten},\n",
        "  journal={Protein Science},\n",
        "  volume={34},\n",
        "  number={1},\n",
        "  pages={e5233},\n",
        "  year={2025},\n",
        "  publisher={Wiley Online Library}\n",
        "}\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "0NULd4ycW4dw"
      }
    }
  ]
}